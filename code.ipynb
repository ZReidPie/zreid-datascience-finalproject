{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setting Up and Using the AniList API**\n",
    "\n",
    "### **Tip 1**: Use a virtual environment to keep your dependencies isolated.  \n",
    "### **Tip 2**: Don’t worry about tokens expiring—they last a long time.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1: Register Your Application on AniList**\n",
    "\n",
    "1. **Go to AniList Developer Settings**:  \n",
    "   - [AniList Developer Settings](https://anilist.co/settings/developer).\n",
    "   - [Heres the docs aswell](https://docs.anilist.co/guide/graphql/).\n",
    "\n",
    "2. **Create a New Application**:\n",
    "   - If you don’t have an AniList account, create one.\n",
    "   - **Application Name**: Choose a memorable name.\n",
    "   - **Redirect URL**: Use a dummy URL like `https://example.com/callback`.  \n",
    "     *(No web development is needed; this is just for OAuth).*\n",
    "\n",
    "3. **Save the Application**:\n",
    "   - You’ll receive:\n",
    "     - **Client ID**\n",
    "     - **Client Secret**\n",
    "   - **Important**: Save these securely.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2: Obtain an Authorization Code**\n",
    "\n",
    "### **Why Use Authorization Code Grant?**\n",
    "We’ll hide sensitive keys in a `.env` file and add it to `.gitignore` for security.\n",
    "\n",
    "### **Construct the Authorization URL**  \n",
    "Replace placeholders with your actual values:\n",
    "https://anilist.co/api/v2/oauth/authorize?client_id=YOUR_CLIENT_ID&response_type=code&redirect_uri=YOUR_REDIRECT_URI\n",
    "\n",
    "\n",
    "### 1. **Open the URL in a Browser**\n",
    "\n",
    "- Log in to AniList.\n",
    "- Grant permissions to your app.\n",
    "- You’ll be redirected to your specified redirect URL, which includes the AUTH_CODE as a query parameter (e.g., https://example.com/callback?code=AUTH_CODE).\n",
    "\n",
    "\n",
    "#### 2. **Copy the `AUTH_CODE` from the Redirect URL and save it to the `.env` file**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3: Exchange Authorization Code for Access Token**\n",
    "\n",
    "1. **Create a `.env` File**:  \n",
    "   Store your credentials securely in the following format:\n",
    "\n",
    "   CLIENT_ID=\"{INSERT}\"\n",
    "\n",
    "   CLIENT_SECRET=\"{INSERT}\"\n",
    "\n",
    "   REDIRECT_URI=\"{INSERT}\"\n",
    "   \n",
    "   AUTH_CODE=\"{INSERT}\"\n",
    "\n",
    "2. **Run the First Code Cell**:\n",
    "\n",
    "This makes a POST request to AniList's `token_url` and retrieves the `ACCESS_TOKEN`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "CLIENT_ID = os.getenv('CLIENT_ID')\n",
    "CLIENT_SECRET = os.getenv('CLIENT_SECRET')\n",
    "REDIRECT_URI = os.getenv('REDIRECT_URI')\n",
    "ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')\n",
    "AUTH_CODE = os.getenv('AUTH_CODE')\n",
    "\n",
    "# Token request payload\n",
    "token_url = 'https://anilist.co/api/v2/oauth/token' # public endpoint for Anilist \n",
    "payload = {\n",
    "    'grant_type': 'authorization_code',\n",
    "    'client_id': CLIENT_ID,\n",
    "    'client_secret': CLIENT_SECRET,\n",
    "    'redirect_uri': REDIRECT_URI,\n",
    "    'code': AUTH_CODE\n",
    "}\n",
    "\n",
    "# Send POST request to exchange code for access token\n",
    "response = requests.post(token_url, data=payload)\n",
    "token_data = response.json()\n",
    "\n",
    "# Print the access token\n",
    "\n",
    "# Uncomment this, doesn't work after a couple of tries to mark down result\n",
    "#print(\"Access Token:\", token_data['access_token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Add the ACCESS_TOKEN to Your .env File:**\n",
    "    \n",
    "    ACCESS_TOKEN=\"{INSERT}\"\n",
    "\n",
    "4. **Testing json data**\n",
    "\n",
    "    Now run the cell below to test if you can fetch the anime json data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'Media': {'id': 1, 'title': {'romaji': 'Cowboy Bebop', 'english': 'Cowboy Bebop', 'native': 'カウボーイビバップ'}, 'format': 'TV', 'episodes': 26, 'status': 'FINISHED', 'averageScore': 86, 'popularity': 372252, 'genres': ['Action', 'Adventure', 'Drama', 'Sci-Fi']}}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Your access token\n",
    "ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')\n",
    "\n",
    "# Authorization headers\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {ACCESS_TOKEN}'\n",
    "}\n",
    "\n",
    "# GraphQL query to fetch anime details\n",
    "query = '''\n",
    "query ($id: Int) {\n",
    "  Media(id: $id, type: ANIME) {\n",
    "    id\n",
    "    title {\n",
    "      romaji\n",
    "      english\n",
    "      native\n",
    "    }\n",
    "    format\n",
    "    episodes\n",
    "    status\n",
    "    averageScore\n",
    "    popularity\n",
    "    genres\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "# Variables for the query\n",
    "variables = {\n",
    "    'id': 1  # Example ID for \"Cowboy Bebop\"\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "url = 'https://graphql.anilist.co'\n",
    "response = requests.post(url, json={'query': query, 'variables': variables}, headers=headers)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result for the last response should be \n",
    "\n",
    "{'data': {'Media': {'id': 1, 'title': {'romaji': 'Cowboy Bebop', 'english': 'Cowboy Bebop', 'native': 'カウボーイビバップ'}, 'format': 'TV', 'episodes': 26, 'status': 'FINISHED', 'averageScore': 86, 'popularity': 372155, 'genres': ['Action', 'Adventure', 'Drama', 'Sci-Fi']}}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to train a machine learning model using data collected from the AniList API to predict an anime's true rating based on a variety of factors. The features used in the training process include attributes such as studio, number of episodes, season, popularity, favorites, and other relevant metrics.\n",
    "\n",
    "At the end of the project, the model should be able to take a valid anime title as input, calculate its predicted \"true rating,\" and compare the result to the original rating listed on AniList. This approach aims to provide insights into how various factors contribute to an anime's rating and evaluate the model's predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 500 TV anime and saved to 'data/raw_anilist.csv'\n"
     ]
    }
   ],
   "source": [
    "# Anilist Fetching animes and making CSV file \n",
    "import requests\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Your AniList access token\n",
    "ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')\n",
    "\n",
    "# Authorization headers\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {ACCESS_TOKEN}'\n",
    "}\n",
    "\n",
    "# GraphQL query to fetch anime details (only TV format)\n",
    "query = '''\n",
    "query ($page: Int, $perPage: Int) {\n",
    "  Page(page: $page, perPage: $perPage) {\n",
    "    media(type: ANIME, format: TV) {\n",
    "      id\n",
    "      title {\n",
    "        romaji\n",
    "        english\n",
    "      }\n",
    "      episodes\n",
    "      status\n",
    "      averageScore\n",
    "      popularity\n",
    "      favourites\n",
    "      genres\n",
    "      studios {\n",
    "        edges {\n",
    "          node {\n",
    "            name\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      source\n",
    "      season\n",
    "      startDate {\n",
    "        year\n",
    "        month\n",
    "        day\n",
    "      }\n",
    "      endDate {\n",
    "        year\n",
    "        month\n",
    "        day\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "# Function to fetch anime details\n",
    "def fetch_anime_details(pages_to_fetch=10, animes_per_page=50):\n",
    "    anime_list = []\n",
    "\n",
    "    for page in range(1, pages_to_fetch + 1):\n",
    "        # Variables for the query\n",
    "        variables = {\n",
    "            'page': page,\n",
    "            'perPage': animes_per_page\n",
    "        }\n",
    "        \n",
    "        # Make the request\n",
    "        url = 'https://graphql.anilist.co'\n",
    "        response = requests.post(url, json={'query': query, 'variables': variables}, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            anime_list.extend(data['data']['Page']['media'])\n",
    "        else:\n",
    "            print(f\"Error fetching page {page}: {response.status_code}, {response.text}\")\n",
    "            break\n",
    "\n",
    "        # Delay to respect API limits\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    return anime_list\n",
    "\n",
    "# Fetch anime details\n",
    "# change later to fetch 500\n",
    "anime_data = fetch_anime_details(pages_to_fetch=10, animes_per_page=5)\n",
    "\n",
    "# Process the data into a DataFrame\n",
    "processed_anime_data = []\n",
    "\n",
    "for anime in anime_data:\n",
    "    studios = \", \".join([studio['node']['name'] for studio in anime['studios']['edges']])\n",
    "    start_date = f\"{anime['startDate']['year']}-{anime['startDate']['month']}-{anime['startDate']['day']}\" if anime['startDate'] else None\n",
    "    end_date = f\"{anime['endDate']['year']}-{anime['endDate']['month']}-{anime['endDate']['day']}\" if anime['endDate'] else None\n",
    "    processed_anime_data.append({\n",
    "        'id': anime['id'],\n",
    "        'title_romaji': anime['title']['romaji'],\n",
    "        'title_english': anime['title']['english'],\n",
    "        'episodes': anime['episodes'],\n",
    "        'status': anime['status'],\n",
    "        'average_score': anime['averageScore'],\n",
    "        'popularity': anime['popularity'],\n",
    "        'favourites': anime['favourites'],\n",
    "        'genres': \", \".join(anime['genres']),\n",
    "        'studios': studios,\n",
    "        'source': anime['source'],\n",
    "        'season': anime['season'],\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(processed_anime_data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('data/raw_anilist.csv', index=False)\n",
    "\n",
    "print(\"Fetched 500 TV anime and saved to 'data/raw_anilist.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                title_romaji           title_english  episodes  \\\n",
      "0    1                Cowboy Bebop            Cowboy Bebop      26.0   \n",
      "1    6                      TRIGUN                  Trigun      26.0   \n",
      "2    7          Witch Hunter ROBIN      Witch Hunter ROBIN      26.0   \n",
      "3    8              Bouken Ou Beet  Beet the Vandel Buster      52.0   \n",
      "4   15                Eyeshield 21            Eyeshield 21     145.0   \n",
      "5   16        Hachimitsu to Clover        Honey and Clover      24.0   \n",
      "6   17  Hungry Heart: Wild Striker                     NaN      52.0   \n",
      "7   18      Initial D FOURTH STAGE     Initial D 4th Stage      24.0   \n",
      "8   19                     MONSTER                 Monster      74.0   \n",
      "9   20                      NARUTO                  Naruto     220.0   \n",
      "10  21                   ONE PIECE               ONE PIECE       NaN   \n",
      "11  22         Tennis no Ouji-sama    The Prince of Tennis     178.0   \n",
      "12  23            Ring ni Kakero 1                     NaN      12.0   \n",
      "13  24               School Rumble           School Rumble      26.0   \n",
      "14  25                   Sunabouzu             Desert Punk      24.0   \n",
      "\n",
      "       status  average_score  popularity  favourites  \\\n",
      "0    FINISHED             86      372252       24316   \n",
      "1    FINISHED             80      133477        5274   \n",
      "2    FINISHED             68       18157         204   \n",
      "3    FINISHED             65        2555          29   \n",
      "4    FINISHED             76       28520         662   \n",
      "5    FINISHED             76       49595         816   \n",
      "6    FINISHED             71        4066          71   \n",
      "7    FINISHED             80       39032         770   \n",
      "8    FINISHED             88      249214       17502   \n",
      "9    FINISHED             79      571389       27314   \n",
      "10  RELEASING             88      567668       82301   \n",
      "11   FINISHED             75       30164         623   \n",
      "12   FINISHED             60        1381          18   \n",
      "13   FINISHED             76       49966         975   \n",
      "14   FINISHED             68       23793         304   \n",
      "\n",
      "                                               genres  \\\n",
      "0                    Action, Adventure, Drama, Sci-Fi   \n",
      "1            Action, Adventure, Comedy, Drama, Sci-Fi   \n",
      "2                Action, Drama, Mystery, Supernatural   \n",
      "3                    Adventure, Fantasy, Supernatural   \n",
      "4                              Action, Comedy, Sports   \n",
      "5               Comedy, Drama, Romance, Slice of Life   \n",
      "6                       Comedy, Slice of Life, Sports   \n",
      "7                               Action, Drama, Sports   \n",
      "8     Drama, Horror, Mystery, Psychological, Thriller   \n",
      "9   Action, Adventure, Comedy, Drama, Fantasy, Sup...   \n",
      "10          Action, Adventure, Comedy, Drama, Fantasy   \n",
      "11                             Action, Comedy, Sports   \n",
      "12                                     Action, Sports   \n",
      "13                     Comedy, Romance, Slice of Life   \n",
      "14           Action, Adventure, Comedy, Ecchi, Sci-Fi   \n",
      "\n",
      "                                              studios    source  season  \\\n",
      "0        Sunrise, Bandai Visual, Bandai Entertainment  ORIGINAL  SPRING   \n",
      "1       MADHOUSE, Nippon Victor, Arts Pro, Funimation     MANGA  SPRING   \n",
      "2        Sunrise, Bandai Visual, Bandai Entertainment  ORIGINAL  SUMMER   \n",
      "3                    Toei Animation, Dentsu, TV Tokyo     MANGA    FALL   \n",
      "4   Studio Gallop, NAS, Nihon Ad Systems, Sentai F...     MANGA  SPRING   \n",
      "5   J.C. Staff, Nomad, Genco, Viz Media, Asmik Ace...     MANGA  SPRING   \n",
      "6                           Nippon Animation, Fuji TV     MANGA    FALL   \n",
      "7      OB Planning, Funimation, A.C.G.T., Studio Jack     MANGA  SPRING   \n",
      "8   MADHOUSE, VAP, Viz Media, Nippon Television Ne...     MANGA  SPRING   \n",
      "9   Studio Pierrot, TV Tokyo, Aniplex, Viz Media, ...     MANGA    FALL   \n",
      "10  Toei Animation, Funimation, Fuji TV, 4Kids Ent...     MANGA    FALL   \n",
      "11  Production I.G, Trans Arts, Viz Media, NAS, Fu...     MANGA    FALL   \n",
      "12            Toei Animation, Marvelous Entertainment     MANGA    FALL   \n",
      "13  TV Tokyo, Sotsu, Marvelous Entertainment, Star...     MANGA    FALL   \n",
      "14           GONZO, GDH, Funimation, Pony Canyon, CBC     MANGA    FALL   \n",
      "\n",
      "    start_date        end_date  \n",
      "0     1998-4-3       1999-4-24  \n",
      "1     1998-4-1       1998-9-30  \n",
      "2     2002-7-2      2002-12-24  \n",
      "3    2004-9-30       2005-9-29  \n",
      "4     2005-4-6       2008-3-19  \n",
      "5    2005-4-15       2005-9-27  \n",
      "6    2002-9-11       2003-9-10  \n",
      "7    2004-4-17       2006-2-18  \n",
      "8     2004-4-7       2005-9-28  \n",
      "9    2002-10-3        2007-2-8  \n",
      "10  1999-10-20  None-None-None  \n",
      "11  2001-10-10       2005-3-23  \n",
      "12   2004-10-6      2004-12-15  \n",
      "13   2004-10-5       2005-3-29  \n",
      "14   2004-10-6       2005-3-30  \n"
     ]
    }
   ],
   "source": [
    "# lets view our rows to make sure everything is there \n",
    "print(pd.read_csv(file_path, nrows=15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed. 'train.csv' and 'test.csv' have been saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "# Specify the file path for the dataset containing anime details\n",
    "file_path = 'data/raw_anilist.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "# Use an 80-20 split: 80% of the data will be used for training, 20% for testing\n",
    "# random_state ensures reproducibility of the split\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Save the splits to separate CSV files\n",
    "# Save the training data to 'train.csv' for model training\n",
    "train_data.to_csv('data/train.csv', index=False) # Ensure the index is not included in the saved file\n",
    "# Save the testing data to 'test.csv' for model evaluation\n",
    "test_data.to_csv('data/test.csv', index=False)\n",
    "\n",
    "# Step 4: Confirmation message\n",
    "print(\"Data split completed. 'train.csv' and 'test.csv' have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Import the pandas library for data manipulation and analysis\n",
    "# Step 1: Define file paths for training and testing data\n",
    "# Specify the file paths for the training and testing datasets\n",
    "train_path = 'data/train.csv'\n",
    "test_path = 'data/test.csv'\n",
    "\n",
    "# Step 2: Load the data into DataFrames\n",
    "# Use pandas to read the CSV files and load them into DataFrames\n",
    "train_df = pd.read_csv(train_path) # Load the training dataset into 'train_df'\n",
    "test_df = pd.read_csv(test_path) # Load the testing dataset into 'test_df'\n",
    "\n",
    "# At this point, 'train_df' contains the data for training the model,\n",
    "# and 'test_df' contains the data for evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def preprocess_and_engineer_features(df):\n",
    "    # Convert start and end dates to datetime\n",
    "    df['start_date'] = pd.to_datetime(df['start_date'], errors='coerce')\n",
    "    df['end_date'] = pd.to_datetime(df['end_date'], errors='coerce')\n",
    "\n",
    "    # Extract year from start date\n",
    "    df['start_year'] = df['start_date'].dt.year.fillna(0).astype(int)\n",
    "    df['end_year'] = df['end_date'].dt.year.fillna(0).astype(int)\n",
    "\n",
    "    # Encode season numerically (e.g., SPRING = 1, SUMMER = 2, etc.)\n",
    "    season_mapping = {'WINTER': 1, 'SPRING': 2, 'SUMMER': 3, 'FALL': 4}\n",
    "    df['season_encoded'] = df['season'].map(season_mapping).fillna(0).astype(int)\n",
    "\n",
    "    # Calculate anime runtime in days\n",
    "    df['runtime_days'] = (df['end_date'] - df['start_date']).dt.days.fillna(0).astype(int)\n",
    "\n",
    "    # Log-transform numerical features to reduce skewness\n",
    "    df['log_popularity'] = np.log1p(df['popularity'])\n",
    "    df['log_favorites'] = np.log1p(df['favourites'])\n",
    "\n",
    "    # One-hot encode genres (can handle multiple genres per anime)\n",
    "    df['genres'] = df['genres'].str.split(', ')  # Split genres into lists\n",
    "    genre_dummies = df['genres'].explode().str.get_dummies().groupby(level=0).sum()\n",
    "    df = pd.concat([df, genre_dummies], axis=1)\n",
    "\n",
    "    # Studios encoding (use a frequency encoding)\n",
    "    studio_counts = df['studios'].value_counts().to_dict()\n",
    "    df['studio_frequency'] = df['studios'].map(studio_counts).fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess datasets\n",
    "train_df = preprocess_and_engineer_features(train_df)\n",
    "test_df = preprocess_and_engineer_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_romaji</th>\n",
       "      <th>title_english</th>\n",
       "      <th>episodes</th>\n",
       "      <th>status</th>\n",
       "      <th>average_score</th>\n",
       "      <th>popularity</th>\n",
       "      <th>favourites</th>\n",
       "      <th>genres</th>\n",
       "      <th>studios</th>\n",
       "      <th>...</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Psychological</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Slice of Life</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Supernatural</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>studio_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>Ring ni Kakero 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>60</td>\n",
       "      <td>1381</td>\n",
       "      <td>18</td>\n",
       "      <td>[Action, Sports]</td>\n",
       "      <td>Toei Animation, Marvelous Entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      title_romaji title_english  episodes    status  average_score  \\\n",
       "0  23  Ring ni Kakero 1           NaN      12.0  FINISHED             60   \n",
       "\n",
       "   popularity  favourites            genres  \\\n",
       "0        1381          18  [Action, Sports]   \n",
       "\n",
       "                                   studios  ... Music Mystery Psychological  \\\n",
       "0  Toei Animation, Marvelous Entertainment  ...     0       0             0   \n",
       "\n",
       "  Romance  Sci-Fi  Slice of Life  Sports  Supernatural  Thriller  \\\n",
       "0       0       0              0       1             0         0   \n",
       "\n",
       "   studio_frequency  \n",
       "0                 1  \n",
       "\n",
       "[1 rows x 39 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_romaji</th>\n",
       "      <th>title_english</th>\n",
       "      <th>episodes</th>\n",
       "      <th>status</th>\n",
       "      <th>average_score</th>\n",
       "      <th>popularity</th>\n",
       "      <th>favourites</th>\n",
       "      <th>genres</th>\n",
       "      <th>studios</th>\n",
       "      <th>...</th>\n",
       "      <th>Ecchi</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Mecha</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Psychological</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Slice of Life</th>\n",
       "      <th>studio_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>School Rumble</td>\n",
       "      <td>School Rumble</td>\n",
       "      <td>26.0</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>76</td>\n",
       "      <td>49966</td>\n",
       "      <td>975</td>\n",
       "      <td>[Comedy, Romance, Slice of Life]</td>\n",
       "      <td>TV Tokyo, Sotsu, Marvelous Entertainment, Star...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   title_romaji  title_english  episodes    status  average_score  \\\n",
       "0  24  School Rumble  School Rumble      26.0  FINISHED             76   \n",
       "\n",
       "   popularity  favourites                            genres  \\\n",
       "0       49966         975  [Comedy, Romance, Slice of Life]   \n",
       "\n",
       "                                             studios  ... Ecchi Fantasy  \\\n",
       "0  TV Tokyo, Sotsu, Marvelous Entertainment, Star...  ...     0       0   \n",
       "\n",
       "  Horror Mecha  Mystery  Psychological  Romance  Sci-Fi  Slice of Life  \\\n",
       "0      0     0        0              0        1       0              1   \n",
       "\n",
       "   studio_frequency  \n",
       "0                 1  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE: 3.0174\n",
      "Validation RMSE: 3.6896\n",
      "Submission file 'submission.csv' created successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Define target and features\n",
    "target = 'average_score'\n",
    "features = train_df.drop(columns=['id', 'start_date', 'end_date', target])  # Drop unnecessary columns\n",
    "test_features = test_df.drop(columns=['id', 'start_date', 'end_date', target])\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = features.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = features.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessors\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocess datasets\n",
    "X_train_full = features\n",
    "X_test_full = test_features\n",
    "y_train_full = train_df[target]\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess features\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_val = preprocessor.transform(X_val)\n",
    "X_test = preprocessor.transform(X_test_full)\n",
    "\n",
    "# Train the model (XGBoost Regressor)\n",
    "model = XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    max_depth=20,\n",
    "    learning_rate=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "# Predict on the test dataset\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Create a submission file\n",
    "submission = test_df.copy()\n",
    "submission['true_rating'] = test_predictions\n",
    "submission[['title_romaji', 'average_score', 'true_rating']].to_csv('data/submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            title_romaji  average_score  true_rating\n",
      "0          School Rumble             76    78.002860\n",
      "1              Black Cat             69    72.009840\n",
      "2                Chobits             70    77.049540\n",
      "3      Soukyuu no Fafner             69    60.284450\n",
      "4       Yakitate!! Japan             75    70.415060\n",
      "5               SHUFFLE!             65    68.347466\n",
      "6            Arc the Lad             61    57.632355\n",
      "7          Ai Yori Aoshi             67    65.878880\n",
      "8              D.N.Angel             66    67.905426\n",
      "9  Shin Seiki Evangelion             83    87.948590\n",
      "\n",
      "Validation MAE: 3.0174\n",
      "Validation RMSE: 3.6896\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.read_csv('data/submission.csv')\n",
    "# Replace 'column_name' with the actual column you want to view\n",
    "print(submission_df.head(10))\n",
    "print(\"\")\n",
    "print(f\"Validation MAE: {val_mae:.4f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
